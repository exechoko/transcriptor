
# ğŸ§  Whisper API - TranscripciÃ³n de audio con FastAPI + Whisper

Este proyecto es una API simple construida con FastAPI y OpenAI Whisper (modo CPU), que permite subir un archivo de audio y obtener la transcripciÃ³n en texto.

---

## ğŸš€ Levantar el servicio con Docker

### 1. Clonar el repositorio (o navegar al directorio del proyecto)

```bash
https://github.com/exechoko/transcriptor.git
cd transcriptor
```

### 2. Construir e iniciar los contenedores

```bash
docker compose up --build
```

Esto construirÃ¡ la imagen e iniciarÃ¡ la API en `http://localhost:8010`.

---

## ğŸ›‘ Detener el servicio

```bash
docker compose down
```

---

## ğŸ§ª Endpoints disponibles

### `GET /`
Verifica si la API estÃ¡ activa.

**Respuesta esperada:**
```json
{
  "message": "API activa"
}
```

---

### `POST /transcribe/`
Sube un archivo de audio y devuelve la transcripciÃ³n.

#### ParÃ¡metros:
- Formato: `multipart/form-data`
- Campo: `file` (archivo de audio, por ejemplo `.mp3`, `.wav`, `.m4a`, etc.)

#### Ejemplo con `curl`:
```bash
curl.exe -X POST "http://localhost:8010/transcribe/"
  -H "accept: application/json"
  -H "Content-Type: multipart/form-data"
  -F "file=@C:/Users/Usuario/Desktop/saludo.wav"
```

#### Respuesta esperada:
```json
{
  "success": true,
  "text": "Texto transcripto desde el audio"
}
```

#### En caso de error:
```json
{
  "success": false,
  "text": "DescripciÃ³n del error"
}
```

---

## ğŸ“ Estructura del proyecto

```
.
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ main.py              # API FastAPI
â”‚   â””â”€â”€ transcribir.py       # FunciÃ³n de transcripciÃ³n con Whisper
â”œâ”€â”€ requirements.txt         # Dependencias del proyecto
â”œâ”€â”€ Dockerfile               # Imagen base de la app
â”œâ”€â”€ docker-compose.yml       # OrquestaciÃ³n del contenedor
â””â”€â”€ README.md                # Esta guÃ­a
```

---

## ğŸ“Œ Notas
- El modelo `base` de Whisper se carga una Ãºnica vez al iniciar el contenedor.
- La carpeta temporal `/tmp/audio` se usa para almacenar los audios de forma transitoria.
- Este proyecto utiliza PyTorch en modo CPU (`torch==2.1.0+cpu`), por lo tanto **no requiere GPU**.

---

ğŸ’¡ **Tip**: podÃ©s probar la API visualmente en `http://localhost:8010/docs` gracias a la documentaciÃ³n automÃ¡tica de Swagger.

---
